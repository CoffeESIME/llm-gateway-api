"""
Script de prueba para validar el funcionamiento de embeddings.

Prueba 1: Calidad semÃ¡ntica del modelo BGE-M3
  - Compara texto crudo vs texto enriquecido con conceptos (Graph RAG)
  - Verifica que el enriquecimiento mejore la similitud semÃ¡ntica

Prueba 2: Funcionamiento via API
  - Llama a los endpoints REST del gateway para texto, batch e info

Uso local (directo):
  python scripts/test_embedding_quality.py

Uso via API (requiere servidor corriendo):
  python scripts/test_embedding_quality.py --api
"""
import argparse
import sys
import os

# Agregar el directorio raÃ­z del proyecto al path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def test_local_embedding_quality():
    """
    Prueba directa: carga el modelo via EmbeddingService del proyecto
    y valida calidad semÃ¡ntica con el caso de la "Cabra" de Terray.
    """
    import torch
    from services.embedding_service import embedding_service

    print("\n" + "=" * 60)
    print("ğŸ§ª PRUEBA 1: Calidad SemÃ¡ntica (BGE-M3 via EmbeddingService)")
    print("=" * 60)

    # Info del servicio
    info = embedding_service.get_model_info()
    print(f"ğŸ“Œ Dispositivo: {info['device'].upper()}")
    print(f"ğŸ“Œ Modelo texto: {info['models']['text']['model_id']}")
    print(f"ğŸ“Œ Dimensiones: {info['models']['text']['dimensions']}")

    # â”€â”€â”€ Caso de prueba: Texto crudo vs enriquecido â”€â”€â”€
    text_raw = (
        "Yo no era un alpinista intelectual, sino un animal fogoso "
        "que saltaba de cima en cima como una cabra."
    )

    text_enriched = (
        "Yo no era un alpinista intelectual, sino un animal fogoso "
        "que saltaba de cima en cima como una cabra. "
        "Conceptos Clave: Agilidad, Ãmpetu, Libertad, PasiÃ³n, Instinto, Naturaleza."
    )

    # Query difÃ­cil: "Libertad" NO aparece en el texto crudo
    query = "La sensaciÃ³n de libertad fÃ­sica y destreza"

    print(f"\nğŸ” QUERY: '{query}'")
    print(f"ğŸ“„ TEXTO CRUDO: '{text_raw[:80]}...'")
    print(f"âœ¨ TEXTO ENRIQUECIDO: '{text_enriched[:80]}...'")

    # â”€â”€â”€ Generar embeddings â”€â”€â”€
    print("\nğŸ”„ Vectorizando con EmbeddingService...")
    vec_query = embedding_service.embed_text(query)
    vec_raw = embedding_service.embed_text(text_raw)
    vec_enriched = embedding_service.embed_text(text_enriched)

    # Verificar dimensiones
    assert len(vec_query) == info['models']['text']['dimensions'], \
        f"Dimensiones incorrectas: {len(vec_query)} vs {info['models']['text']['dimensions']}"

    # â”€â”€â”€ Calcular similitud coseno â”€â”€â”€
    t_query = torch.tensor(vec_query)
    t_raw = torch.tensor(vec_raw)
    t_enriched = torch.tensor(vec_enriched)

    score_raw = torch.nn.functional.cosine_similarity(t_query.unsqueeze(0), t_raw.unsqueeze(0)).item()
    score_enriched = torch.nn.functional.cosine_similarity(t_query.unsqueeze(0), t_enriched.unsqueeze(0)).item()

    # â”€â”€â”€ Resultados â”€â”€â”€
    print("\n" + "-" * 40)
    print(f"ğŸ“„ TEXTO CRUDO (Score):      {score_raw:.4f}")
    print(f"âœ¨ TEXTO ENRIQUECIDO (Score): {score_enriched:.4f}")
    print("-" * 40)

    diff = score_enriched - score_raw
    if diff > 0.05:
        print(f"âœ… Ã‰XITO: El enriquecimiento mejorÃ³ la bÃºsqueda en {(diff*100):.2f}%")
    elif diff > 0:
        print(f"âš ï¸ MEJORA LEVE: +{(diff*100):.2f}%")
    else:
        print("âŒ FALLO: El enriquecimiento no mejorÃ³ la bÃºsqueda")

    return score_raw, score_enriched


def test_batch_embeddings():
    """
    Prueba de batch embeddings y verificaciÃ³n de consistencia.
    """
    import torch
    from services.embedding_service import embedding_service

    print("\n" + "=" * 60)
    print("ğŸ§ª PRUEBA 2: Batch Embeddings")
    print("=" * 60)

    texts = [
        "El gato duerme en el sofÃ¡",
        "El perro corre por el parque",
        "Python es un lenguaje de programaciÃ³n",
        "La temperatura del reactor es de 350 grados",
    ]

    print(f"ğŸ“ Procesando {len(texts)} textos en batch...")
    vectors = embedding_service.embed_texts_batch(texts)

    assert len(vectors) == len(texts), f"Se esperaban {len(texts)} vectores, se obtuvieron {len(vectors)}"
    print(f"âœ… Vectores generados: {len(vectors)}, dimensiones: {len(vectors[0])}")

    # Matriz de similitud
    t_vectors = torch.tensor(vectors)
    sim_matrix = torch.nn.functional.cosine_similarity(
        t_vectors.unsqueeze(1), t_vectors.unsqueeze(0), dim=2
    )

    print("\nğŸ“Š Matriz de Similitud:")
    print(f"{'':>6}", end="")
    for i in range(len(texts)):
        print(f"  T{i}   ", end="")
    print()

    for i in range(len(texts)):
        print(f"T{i}  ", end="")
        for j in range(len(texts)):
            score = sim_matrix[i][j].item()
            marker = " *" if i != j and score > 0.7 else "  "
            print(f" {score:.3f}{marker}", end="")
        print(f"  â† {texts[i][:35]}...")

    # Los textos del gato y perro (ambos animales) deben ser mÃ¡s similares
    # que gato vs programaciÃ³n
    sim_gato_perro = sim_matrix[0][1].item()
    sim_gato_python = sim_matrix[0][2].item()

    print(f"\nğŸ±ğŸ¶ Gato-Perro: {sim_gato_perro:.4f}")
    print(f"ğŸ±ğŸ’» Gato-Python: {sim_gato_python:.4f}")

    if sim_gato_perro > sim_gato_python:
        print("âœ… Correcto: Textos semÃ¡nticamente similares tienen mayor score")
    else:
        print("âŒ Inesperado: La similitud semÃ¡ntica no es coherente")


def test_api_endpoints():
    """
    Prueba los endpoints REST del gateway.
    Requiere que el servidor estÃ© corriendo.
    """
    import requests

    BASE_URL = os.getenv("LLM_GATEWAY_URL", "http://localhost:8100")
    print("\n" + "=" * 60)
    print(f"ğŸ§ª PRUEBA 3: API Endpoints ({BASE_URL})")
    print("=" * 60)

    # Test 1: Embedding de texto individual
    print("\nğŸ“ POST /v1/embeddings/text")
    try:
        resp = requests.post(f"{BASE_URL}/v1/embeddings/text", json={
            "text": "El gato duerme en el sofÃ¡",
            "normalize": True
        }, timeout=30)
        data = resp.json()

        if resp.status_code == 200:
            print(f"   âœ… Status: {resp.status_code}")
            print(f"   ğŸ“ Dimensiones: {data['dimensions']}")
            print(f"   ğŸ·ï¸ Modelo: {data['model']}")
            print(f"   ğŸ“Š Primeros 5 valores: {data['embedding'][:5]}")
        else:
            print(f"   âŒ Error ({resp.status_code}): {data}")
    except requests.ConnectionError:
        print(f"   âš ï¸ No se pudo conectar a {BASE_URL}. Â¿EstÃ¡ el servidor corriendo?")
        return
    except Exception as e:
        print(f"   âŒ Error: {e}")
        return

    # Test 2: Batch embeddings
    print("\nğŸ“ POST /v1/embeddings/text/batch")
    try:
        resp = requests.post(f"{BASE_URL}/v1/embeddings/text/batch", json={
            "texts": [
                "Primera frase de prueba",
                "Segunda frase de prueba",
                "Tercera frase completamente diferente"
            ],
            "normalize": True
        }, timeout=30)
        data = resp.json()

        if resp.status_code == 200:
            print(f"   âœ… Status: {resp.status_code}")
            print(f"   ğŸ“¦ Total vectores: {data['total']}")
            print(f"   ğŸ“ Dimensiones: {len(data['data'][0]['embedding'])}")
        else:
            print(f"   âŒ Error ({resp.status_code}): {data}")
    except Exception as e:
        print(f"   âŒ Error: {e}")

    # Test 3: Info de modelos
    print("\nğŸ“ GET /v1/embeddings/models")
    try:
        resp = requests.get(f"{BASE_URL}/v1/embeddings/models", timeout=10)
        data = resp.json()

        if resp.status_code == 200:
            print(f"   âœ… Status: {resp.status_code}")
            print(f"   ğŸ–¥ï¸ Dispositivo: {data['device']}")
            for modality, model_info in data['models'].items():
                print(f"   ğŸ“Œ {modality}: {model_info['model_id']} ({model_info['dimensions']}d)")
        else:
            print(f"   âŒ Error ({resp.status_code}): {data}")
    except Exception as e:
        print(f"   âŒ Error: {e}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Pruebas de embeddings del LLM Gateway")
    parser.add_argument("--api", action="store_true", help="Probar endpoints REST (requiere servidor)")
    parser.add_argument("--skip-local", action="store_true", help="Saltar pruebas locales (solo API)")
    args = parser.parse_args()

    print("ğŸš€ Test de Embeddings - LLM Gateway")
    print("=" * 60)

    if not args.skip_local:
        test_local_embedding_quality()
        test_batch_embeddings()

    if args.api:
        test_api_endpoints()

    print("\n" + "=" * 60)
    print("âœ… Todas las pruebas completadas")
    print("=" * 60)
