# Configuraci√≥n de Gemini API

## üîë Configuraci√≥n de API Key

Para usar los modelos de Gemini (Google AI), necesitas configurar tu API key en el archivo `.env`.

### 1. Crear/Editar archivo `.env`

```bash
# Copiar el ejemplo si no existe
cp .env.example .env
```

### 2. Agregar tu API Key de Google

Edita el archivo `.env` y agrega tu API key:

```env
# API Keys
GEMINI_API_KEY=tu-api-key-aqui

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Logging
LOG_LEVEL=INFO
```

**¬øD√≥nde obtener la API key?**
1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crea un nuevo proyecto o selecciona uno existente
3. Genera una nueva API key
4. C√≥piala y p√©gala en el archivo `.env`

---

## üéØ Modelos Configurados

Los modelos de Gemini se usan en modo `privacy_mode=flexible`:

| Tarea | Modo Strict (Local) | Modo Flexible (Cloud) |
|-------|---------------------|----------------------|
| **chat** | `ollama/dolphin-mistral-nemo` | `gemini/gemini-2.0-flash-exp` |
| **vision** | `ollama/qwen3-vl:8b` | `gemini/gemini-2.0-flash-exp` |
| **ocr** | `ollama/deepseek-ocr:3b` | `gemini/gemini-2.0-flash-exp` |

---

## ‚öôÔ∏è Formato de Modelos en LiteLLM

**IMPORTANTE:** Los modelos de Gemini deben usar el formato correcto:

‚úÖ **Correcto:**
```python
"gemini/gemini-2.0-flash-exp"  # Con prefijo gemini/
```

‚ùå **Incorrecto:**
```python
"gemini-2.0-flash-exp"  # Sin prefijo - intentar√° usar Vertex AI
```

**¬øPor qu√©?**
- El prefijo `gemini/` le dice a LiteLLM que use **Google AI API** (con API key)
- Sin el prefijo, LiteLLM asume **Vertex AI** (requiere Google Cloud credentials)

---

## üß™ Verificar Configuraci√≥n

### Test 1: Verificar que la API key se carga

```bash
python -c "from config import settings; print(f'API Key configurada: {bool(settings.gemini_api_key)}')"
```

**Resultado esperado:**
```
API Key configurada: True
```

### Test 2: Probar llamada a Gemini

```bash
python test_multimodal_chat.py
```

O usa curl:

```bash
curl -X POST http://localhost:8765/v1/chat/completions \
  -F 'task=chat' \
  -F 'privacy_mode=flexible' \
  -F 'messages=[{"role":"user","content":"Hola, ¬øc√≥mo est√°s?"}]'
```

**Si funciona correctamente, ver√°s:**
```
‚úÖ Respuesta recibida:
   Modelo: gemini/gemini-2.0-flash-exp
   Respuesta: ¬°Hola! Estoy bien, gracias...
```

---

## üêõ Troubleshooting

### Error: "AuthenticationError"

```
Error de autenticaci√≥n. Verifica tu GEMINI_API_KEY en .env
```

**Soluci√≥n:**
1. Verifica que el archivo `.env` existe en la ra√≠z del proyecto
2. Verifica que `GEMINI_API_KEY` est√° configurado correctamente
3. Aseg√∫rate de que no hay espacios extras: `GEMINI_API_KEY=AIza...` (sin espacios)
4. Reinicia el servidor despu√©s de cambiar el `.env`

### Error: "Vertex AI credentials not found"

```
Could not automatically determine credentials for Vertex AI
```

**Causa:** El modelo no tiene el prefijo `gemini/`

**Soluci√≥n:** Verifica `config.py`:
```python
MODEL_ROUTER = {
    "vision": {
        "flexible": "gemini/gemini-2.0-flash-exp"  # ‚úÖ Correcto
    }
}
```

### Error: "Model not found"

```
Modelo 'gemini/gemini-2.0-flash-exp' no encontrado
```

**Posibles causas:**
1. API key inv√°lida o expirada
2. Modelo no disponible en tu regi√≥n
3. Nombre del modelo incorrecto

**Soluciones:**
1. Verifica la API key en Google AI Studio
2. Prueba otro modelo: `gemini/gemini-1.5-flash`
3. Revisa los [modelos disponibles](https://ai.google.dev/models)

### Error: "Rate limit exceeded"

```
Rate limit excedido
```

**Soluci√≥n:**
1. Espera unos minutos antes de reintentar
2. Considera usar modo `strict` (modelos locales)
3. Aumenta el l√≠mite de rate en Google AI Studio (si es posible)

---

## üìä Logs de Depuraci√≥n

Para ver logs detallados de LiteLLM:

### Opci√≥n 1: Modo Verbose en c√≥digo

Edita `services/llm_client.py`:
```python
litellm.set_verbose = True  # Cambiar a True
```

### Opci√≥n 2: Variable de entorno

```bash
export LITELLM_LOG=DEBUG  # Linux/Mac
set LITELLM_LOG=DEBUG     # Windows CMD
$env:LITELLM_LOG="DEBUG"  # Windows PowerShell

python main.py
```

**Logs √∫tiles:**
- `üì§ Llamando a modelo: gemini/...` - Confirma el modelo usado
- `GEMINI_API_KEY` encontrada - Confirma que la API key se carg√≥
- `Request to https://generativelanguage.googleapis.com/...` - Confirma que usa Google AI API

---

## üîê Seguridad

### ‚ö†Ô∏è NUNCA Subas tu API Key a GitHub

Aseg√∫rate de que `.env` est√° en `.gitignore`:

```bash
# Verificar
cat .gitignore | grep .env
```

**Deber√≠a mostrar:**
```
.env
*.env
```

### üîÑ Rotar API Keys

Si accidentalmente expones tu API key:
1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Revoca la API key comprometida
3. Genera una nueva
4. Actualiza el archivo `.env`

---

## üìö Referencias

- [Google AI Studio](https://makersuite.google.com/)
- [Documentaci√≥n de Google AI](https://ai.google.dev/docs)
- [LiteLLM - Gemini Support](https://docs.litellm.ai/docs/providers/gemini)
- [Modelos disponibles](https://ai.google.dev/models)

---

## ‚úÖ Checklist de Configuraci√≥n

- [ ] Archivo `.env` creado en la ra√≠z del proyecto
- [ ] `GEMINI_API_KEY` configurado con tu API key
- [ ] Modelos en `config.py` usan formato `gemini/modelo-name`
- [ ] API key v√°lida y activa en Google AI Studio
- [ ] Servidor reiniciado despu√©s de cambios en `.env`
- [ ] Test de conexi√≥n exitoso
