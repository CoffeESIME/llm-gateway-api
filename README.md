# LLM Gateway API

API Gateway inteligente con soporte multimodal que enruta automÃ¡ticamente entre modelos locales (Ollama) y cloud (Google Gemini) basÃ¡ndose en privacidad y tipo de tarea.

## ğŸ¯ CaracterÃ­sticas

- **ğŸ­ Multimodal**: Chat, Vision, OCR con soporte para texto, imÃ¡genes, audio y video
- **ğŸ“ Archivos Directos**: Sube archivos multimedia directamente (hasta 100MB)
- **ğŸ” Privacy-First**: Modelos locales para datos sensibles, cloud para mÃ¡ximo rendimiento
- **ğŸš€ Google File API**: Manejo inteligente de archivos grandes (>= 5MB)
- **ğŸ“Š Embeddings**: API separada para embeddings de texto, imagen y audio
- **ğŸ”„ Compatible OpenAI**: Formato de API estÃ¡ndar
- **ğŸ“š FastAPI**: DocumentaciÃ³n Swagger automÃ¡tica

---

## ğŸ“‹ Requisitos

### Software
- **Python 3.10+**
- **Ollama** (para modelos locales)
- **NVIDIA GPU** (opcional, para embeddings acelerados)

### API Keys
- **Google Gemini API Key** (para `privacy_mode=flexible`)

### Modelos Ollama
```bash
ollama pull CognitiveComputations/dolphin-mistral-nemo:latest
ollama pull qwen3-vl:8b
ollama pull deepseek-ocr:3b
```

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar e instalar
cd llm-endpoints
python -m venv venv
.\venv\Scripts\activate  # Windows
pip install -r requirements.txt

# 2. Configurar API Key
copy .env.example .env
# Editar .env y agregar tu GEMINI_API_KEY

# 3. Iniciar servidor
python main.py
```

**Servidor:** http://localhost:8765  
**Docs:** http://localhost:8765/docs

---

## ğŸ“š Endpoints Principales

### 1. Chat Completions `/v1/chat/completions`

Endpoint multimodal con soporte para archivos adjuntos.

**Formato:** `multipart/form-data`

**ParÃ¡metros:**
- `task`: `"chat"` | `"vision"` | `"ocr"`
- `privacy_mode`: `"strict"` (local) | `"flexible"` (cloud)
- `messages`: JSON string con mensajes
- `files`: Archivos multimedia (opcional)

**LÃ­mites de archivos:**
| TamaÃ±o | Estrategia | Privacy Mode |
|--------|------------|--------------|
| < 5MB | Base64 | Cualquiera |
| >= 5MB | Google File API | `flexible` |

#### Ejemplo 1: Chat Simple

```bash
curl -X POST http://localhost:8765/v1/chat/completions \
  -F 'task=chat' \
  -F 'privacy_mode=strict' \
  -F 'messages=[{"role":"user","content":"Resume este texto confidencial"}]'
```

#### Ejemplo 2: Vision con Imagen

```bash
curl -X POST http://localhost:8765/v1/chat/completions \
  -F 'task=vision' \
  -F 'privacy_mode=flexible' \
  -F 'messages=[{"role":"user","content":[{"type":"text","text":"Â¿QuÃ© ves?"},{"type":"image","file_index":0}]}]' \
  -F 'files=@imagen.jpg'
```

#### Ejemplo 3: Audio Grande (Google File API)

```bash
curl -X POST http://localhost:8765/v1/chat/completions \
  -F 'task=vision' \
  -F 'privacy_mode=flexible' \
  -F 'messages=[{"role":"user","content":[{"type":"text","text":"Transcribe"},{"type":"audio","file_index":0}]}]' \
  -F 'files=@audio_large.mp3'
```

---

### 2. Embeddings API

Endpoints separados para embeddings de texto, imagen y audio.

#### 2.1 Texto `/v1/embeddings/text`

```bash
curl -X POST http://localhost:8765/v1/embeddings/text \
  -H "Content-Type: application/json" \
  -d '{"text": "Un texto de ejemplo", "normalize": true}'
```

**Modelo:** `BAAI/bge-m3` (1024 dimensiones)

#### 2.2 Imagen `/v1/embeddings/image`

```bash
curl -X POST http://localhost:8765/v1/embeddings/image \
  -F "file=@imagen.jpg"
```

**Modelo:** `google/siglip-so400m-patch14-384` (1152 dim)

#### 2.3 Audio `/v1/embeddings/audio`

```bash
curl -X POST http://localhost:8765/v1/embeddings/audio \
  -F "file=@audio.wav"
```

**Modelo:** `laion/clap-htsat-unfused` (512 dim)

**Ver:** [`EMBEDDINGS.md`](docs/EMBEDDINGS.md) para documentaciÃ³n completa

---

## ğŸ—ºï¸ Routing de Modelos

### Chat Completions

| Task | Privacy: Strict | Privacy: Flexible |
|------|----------------|-------------------|
| **chat** | `ollama/dolphin-mistral-nemo` | `gemini/gemini-2.5-flash` |
| **vision** | `ollama/qwen3-vl:8b` | `gemini/gemini-2.5-flash` |
| **ocr** | `ollama/deepseek-ocr:3b` | `gemini/gemini-2.5-flash` |

### Embeddings

| Modalidad | Modelo | Dimensiones |
|-----------|--------|-------------|
| **texto** | `BAAI/bge-m3` | 1024 |
| **imagen** | `google/siglip-so400m-patch14-384` | 1152 |
| **audio** | `laion/clap-htsat-unfused` | 512 |

---

## ğŸ“ Estructura del Proyecto

```
llm-endpoints/
â”œâ”€â”€ main.py                      # FastAPI app principal
â”œâ”€â”€ config.py                    # ConfiguraciÃ³n y routing
â”œâ”€â”€ requirements.txt             # Dependencias
â”œâ”€â”€ .env.example                # Template de variables
â”‚
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ chat.py                 # Chat completions multimodal
â”‚   â””â”€â”€ embeddings.py           # Endpoints de embeddings
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ llm_client.py           # Cliente LiteLLM
â”‚   â”œâ”€â”€ router.py               # LÃ³gica de routing
â”‚   â”œâ”€â”€ file_processor.py       # Procesamiento de archivos
â”‚   â”œâ”€â”€ google_file_api.py      # Google File API client
â”‚   â””â”€â”€ embedding_service.py    # Servicio de embeddings
â”‚
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ requests.py             # Schemas de request
â”‚   â””â”€â”€ responses.py            # Schemas de response
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ MULTIMODAL_CHAT.md      # GuÃ­a de uso multimodal
    â”œâ”€â”€ EMBEDDINGS.md           # GuÃ­a de embeddings
    â”œâ”€â”€ GEMINI_CONFIG.md        # ConfiguraciÃ³n de Gemini
    â””â”€â”€ RTX4090_OPTIMIZATIONS.md # Optimizaciones GPU
```

---

## ğŸ”§ Uso Avanzado

### Python SDK

```python
import requests
import json

# Chat simple
response = requests.post(
    "http://localhost:8765/v1/chat/completions",
    data={
        "task": "chat",
        "privacy_mode": "strict",
        "messages": json.dumps([
            {"role": "user", "content": "Hola"}
        ])
    }
)

print(response.json()["choices"][0]["message"]["content"])

# Vision con imagen
with open("imagen.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8765/v1/chat/completions",
        data={
            "task": "vision",
            "privacy_mode": "flexible",
            "messages": json.dumps([{
                "role": "user",
                "content": [
                    {"type": "text", "text": "Describe"},
                    {"type": "image", "file_index": 0}
                ]
            }])
        },
        files=[("files", ("imagen.jpg", f, "image/jpeg"))]
    )
```

---

## ğŸ“ Casos de Uso

### 1. RAG con Embeddings Multimodales
```python
# Generar embeddings de documentos con imÃ¡genes
text_emb = embed_text("Contenido del documento")
image_emb = embed_image("diagrama.png")

# Buscar en base de datos vectorial
results = vector_db.search(query_embedding, top_k=5)
```

### 2. AnÃ¡lisis de ImÃ¡genes Privado
```python
# OCR local de documentos sensibles
response = chat(
    task="ocr",
    privacy_mode="strict",  # Â¡Sin enviar a cloud!
    messages=[...],
    files=["factura.png"]
)
```

### 3. TranscripciÃ³n de Audio Largo
```python
# Audio de 10MB se sube automÃ¡ticamente a Google File API
response = chat(
    task="vision",
    privacy_mode="flexible",
    messages=[...],
    files=["reunion_1hora.mp3"]  # Sube a Google, retorna URI
)
```

---

## ğŸ“Š Monitoreo y Health Check

```bash
# Health check
curl http://localhost:8765/health

# Listar modelos
curl http://localhost:8765/v1/models

# Info de embeddings
curl http://localhost:8765/v1/embeddings/models
```

---

## ğŸ› Troubleshooting

### Error: "Modelo no encontrado"
```bash
# Verificar Ollama
ollama list

# Descargar modelo especÃ­fico
ollama pull CognitiveComputations/dolphin-mistral-nemo:latest
```

### Error: AutenticaciÃ³n Gemini
```bash
# Verificar .env
cat .env | grep GEMINI_API_KEY

# Obtener nueva API key
# https://makersuite.google.com/app/apikey
```

### Archivo grande + privacy_mode=strict
```
Error 501: "Procesamiento local de archivos grandes en desarrollo"

SoluciÃ³n: Usar privacy_mode=flexible para archivos >= 5MB
```

---

## ğŸ“– DocumentaciÃ³n Adicional

- **[MULTIMODAL_CHAT.md](docs/MULTIMODAL_CHAT.md)** - GuÃ­a completa de chat multimodal
- **[EMBEDDINGS.md](docs/EMBEDDINGS.md)** - API de embeddings multimodales
- **[GEMINI_CONFIG.md](docs/GEMINI_CONFIG.md)** - Configurar Google Gemini
- **[RTX4090_OPTIMIZATIONS.md](docs/RTX4090_OPTIMIZATIONS.md)** - Optimizaciones GPU

---

## ğŸš€ Optimizaciones

### RTX 4090
- âœ… FP16 automÃ¡tico para embeddings
- âœ… cuDNN benchmark habilitado
- âœ… TF32 para matrix multiplications
- ğŸ“ˆ 2-3x mÃ¡s rÃ¡pido en inferencia

**Ver:** [`RTX4090_OPTIMIZATIONS.md`](docs/RTX4090_OPTIMIZATIONS.md)

---

## ğŸ§ª Testing

```bash
# Tests de chat multimodal
python test_multimodal_chat.py

# Tests de embeddings
python test_embeddings.py
```

---

## ğŸ“ Licencia

MIT

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Abre un issue o pull request.

---

## ğŸ”— Enlaces Ãštiles

- [Google AI Studio](https://makersuite.google.com/)
- [Ollama](https://ollama.ai/)
- [LiteLLM Docs](https://docs.litellm.ai/)
- [FastAPI](https://fastapi.tiangolo.com/)
